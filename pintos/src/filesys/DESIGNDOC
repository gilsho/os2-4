       	 +-------------------------+
		     | CS 140                  |
		     | PROJECT 4: FILE SYSTEMS |
		     | DESIGN DOCUMENT         |
		     +-------------------------+

---- GROUP ----

>> Fill in the names and email addresses of your group members.

Gil Shotan <gilsho@stanford.edu>
Rory MacQueen <macqueen@stanford.edu>
Dan Cocuzzo <dcocuzzo@stanford.edu>


---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Describe briefly which parts of the assignment were implemented by
>> each member of your team. If some team members contributed significantly
>> more or less than others (e.g. 2x), indicate that here.

All parts were implemented together with equal contribution.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

		     INDEXED AND EXTENSIBLE FILES
		     ============================

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

#define UNUSED_WORDS 111

struct inode_disk
  {
    block_sector_t direct[N_DIRECT_PTRS];  /* first-order data sector. */
    block_sector_t indirect;							/* sector containing pointers to other 
    																				sectors*/
    block_sector_t dbl_indirect;					/* doubly indirect sector*/
    off_t length;                          /* File size in bytes. */
    bool is_dir;                           /* True if inode is a director*/
    unsigned magic;                        /* Magic number. */
    uint32_t unused[UNUSED_WORDS];                  /* Not used. */
  };

/* In-memory inode. */
struct inode 
  {
    struct lock lock_dir;               /* used for adding/removing from 
    																			directory */
    struct lock lock_file;              /* Used to check metadata of file */
    bool extending;                     /* flag for if file is currently being 
    																				extended*/
    struct condition ready_to_extend;   /* condition variable to wait on file 
    																				being ready to extend */
  };

>> A2: What is the maximum size of a file supported by your inode
>> structure?  Show your work.

Our inode structure contains 12 direct sector pointers, 1 indirect block
pointer, and 1 doubly-indirect pointer. The indirect block contains 128 
direct sector pointers. The doubly-indirect block contains 128 indirect 
block pointers, which each contain 128 sector pointers. In total, there 
are 12 + 128 + 128^2 data sectors. Since each data sector is 512 bytes, 
the maximum size of a file is: 

(12 + 128 + 128^2) * (512) = 8460288 bytes = 8262 KB


If we include the overheard of allocating metadata, there are 130 
additional sectors (1 for the inode, 129 for indirect pointer tables), 
which brings the total filesize to 8526848 bytes.

---- SYNCHRONIZATION ----

>> A3: Explain how your code avoids a race if two processes attempt to
>> extend a file at the same time.

Before getting the current length of a file, a process must acquire the 
lock for that file. If the process determines that an extension is necessary, 
it first checks to see if the file is already being extended. If it is, then 
the current process must wait on a condition variable until the previous 
extension is complete. Upon waking, it will determine again if an extension is 
necessary.

Right before performing the extension, the process releases the lock, and 
allocates the additional sectors needed. It then writes its data to those
sectors. Once allocation and writing of the extended region is 
complete, the process reacquires the lock and 
updates the file length to reflect the extension. The key point
is that the file length is updated only after the allocation and
writing of data is complete. It will then broadcast to other
processes who are waiting to extend.


>> A4: Suppose processes A and B both have file F open, both
>> positioned at end-of-file.  If A reads and B writes F at the same
>> time, A may read all, part, or none of what B writes.  However, A
>> may not read data other than what B writes, e.g. if B writes
>> nonzero data, A is not allowed to see all zeros.  Explain how your
>> code avoids this race.


Our implementation of file extension guarantees that from the perspective
of process A, file extension by process B is atomic. This is because
process B will only update the file length after the entire allocation and
writing of new sectors is complete. Process A will, therefore, either get 
the 'old' inode length, in which case it is unable to read data that is 
currently being written by process B, or, it gets the new inode length,
in which case process B has completed its writes, so process A can now read
all of the newly extended file's data blocks.

Since process B will synchronously update the file length
only after the extension (allocation and writing) is complete, process A 
will read all or none of the extended file region based on the file length
it observed while briefly acquiring the inode lock prior to reading.


>> A5: Explain how your synchronization design provides "fairness".
>> File access is "fair" if readers cannot indefinitely block writers
>> or vice versa.  That is, many processes reading from a file cannot
>> prevent forever another process from writing the file, and many
>> processes writing to a file cannot prevent another process forever
>> from reading the file.

The only blocking that happens is a file extension blocking 
another file extension. If a process wants to extend the file,
it must wait until ongoing extensions are complete.

Readers and writers that do not extend will never block 
when accessing a file so there is no possibility of readers 
or writers indefinitely blocking each other.

None of these operations hold the lock while reading or writing
data. The lock is only held briefly while checking inode metadata.


---- RATIONALE ----

>> A6: Is your inode structure a multilevel index?  If so, why did you
>> choose this particular combination of direct, indirect, and doubly
>> indirect blocks?  If not, why did you choose an alternative inode
>> structure, and what advantages and disadvantages does your
>> structure have, compared to a multilevel index?

We adopt the multilevel index scheme presented in lecture on our
inode structure, which contains direct, indirect, and doubly
idirect blocks. Given that the filesystem capacity is at most 8 MB,
we chose a combination that would give us a max file size of 8MB. 
Having 1 indirect sector and 1 double indirect sector allows us to
meet this size requirement. 

We also wanted to make sure we had good performace on small files
since the majority of files are relatively small in practice. Having
12 direct sector pointers means that the sectors for the first 
6 KB of a file can be accessed in just one seek.

We include a single sector for indirect pointer entries for improved seek 
times (two seeks) versus doubly indirect accesses (3 seeks).

			    SUBDIRECTORIES
			    ==============

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

/* Constant to set the initial size of a directory to account for
	'.' and '..' */
#define EMPTY_DIR_SIZE (2 * sizeof(struct dir_entry))

/* Current working directory of a process. Stored on thread struct */
struct dir *wdir;

---- ALGORITHMS ----

>> B2: Describe your code for traversing a user-specified path.  How
>> do traversals of absolute and relative paths differ?

Given a valid user-specified path, we first determine if it is an 
absolute path or a relative path by examining the first character;
a leading '/' indicates it will be parsed as an absolute path. If it
is an absolute path, the traversal begins in the root directory; if 
it is a relative path, traversal begins in the process' current working
directory.

Our path traversal algorithm is an iterative approach. We tokenize 
the full path using the '/' delimiter. For each token, we check to 
see if an entry for the token exists in the current directory.
If it does not, then we can simply return false, since the path could
not be resolved. If it is, then the current directory becomes the token
just found, and we repeat the procedure with the next token. Once we
run out of tokens, we can return the inode that we have found. If at any
point we try to open an entry as a directory, and it was NOT a directory
we also return false, since this means that the path was mal-formed.


---- SYNCHRONIZATION ----

>> B4: How do you prevent races on directory entries?  For example,
>> only one of two simultaneous attempts to remove a single file
>> should succeed, as should only one of two simultaneous attempts to
>> create a file with the same name, and so on.

Whenever a process wants to add or remove a file, it must first
acquire the lock for the parent directory. It then checks to
see if that file has already been created/removed. If so, then
it returns from the function. If not, then it can proceed with
its operation, and release the lock only after it has
created/removed the file. In this way, the check for the file's
existence and the creation/removal are together an atomic 
operation. Therefore, we cannot get race conditions on our
directory entries. 


>> B5: Does your implementation allow a directory to be removed if it
>> is open by a process or if it is in use as a process' current
>> working directory?  If so, what happens to that process's future
>> file system operations?  If not, how do you prevent it?

Our implementation allows for an empty directory to be removed, even 
if it is the current process' working directory or if it is in use 
by another process. However, this prevents any process from
creating files in this directory since a process is not allowed to 
create a file in a directory whose inode has been set to be 
removed. Since this directory is by definition empty (only empty
directories can be deleted) no process could read from this 
directory either. 

---- RATIONALE ----

>> B6: Explain why you chose to represent the current directory of a
>> process the way you did.

A process' current working directory is stored as a struct dir on its 
thread structure. We chose to store the working directory on
the thread struct because all threads, including the main thread,
are intialized through thread_create. This is where a process inherits its 
parent process' working directory. The main thread does not have a parent,
so its working directory is set to be root in thread_create.


			     BUFFER CACHE
			     ============

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

#define CACHE_SIZE 50

#define CACHE_WAIT_TIME 10

/* represents a slot in the cache */
struct cache_slot
{
	char data[BLOCK_SECTOR_SIZE];
	/* synchronization */
	int num_accessors; /* number of processes currently accessing this slot */
	bool pending_evict; /* Indicates if slot has been scheduled for eviction */
	bool io_busy;       /* Reading in or writing out slot to disk */
	struct condition io_done; /* signaled when */
	bool dirty;					/* slot has been modified in memory */
	block_sector_t sector; /* sector on disk being stored in slot */
};

struct cache_entry
{
	struct hash_elem h_elem;  /* elem for cache hash */
	struct list_elem l_elem;  /* elem for lru list */
	block_sector_t sector;   /* sector on disk corresponding to this cache entry*/
	int slot; 								/* cache slot for this cache entry */
};

static struct hash cache_hash; /* hash map mapping a sector to the cache slot 
																containing its data*/
static struct cache_slot cache_array[CACHE_SIZE]; /* the cache */
static struct list lru_list; /* cache slots ordered by recent use */

static struct lock lock_map; /* lock for cache map */
static struct lock lock_fetch; /* lock for read-ahead queue */
static struct list qfetch; /* queue of read-ahead requests */
static struct condition cond_fetch; /* signals read-ahead queue not empty */

/* data structure for read-ahead fetch request */
struct fetch_request {
	block_sector_t sector; /* sector on disk to fetch */
	struct list_elem elem; /* elem for read-ahead queue */
};


---- ALGORITHMS ----

>> C2: Describe how your cache replacement algorithm chooses a cache
>> block to evict.

Our cache implements LRU eviction. We maintain
a list of cache slots ordered by accessed time. When sectors that have existing
entries in the cache are accessed due to read/write operations, their cache
slots are moved to the tail of the list. When eviction occurs, the LRU algorithm 
simply pops the slot at the front of the list, which is the least 
recently used slot. 

>> C3: Describe your implementation of write-behind.

When the cache is initialized, a dedicated 'flusher' thread is
spawned. This thread runs in a continuous while loop. It sleeps for 30
seconds, then wakes up and flushes the entire cache by writing all contents
to disk. It repeats this procedure for the entire duration of the program.

>> C4: Describe your implementation of read-ahead.

When the cache is initialized, a dedicated 'fetcher' thread is
spawned. This thread runs in the background, waiting for fetch requests. 
When a process reads data from or writes data to the cache, it requests the 
next sector in the file. The cache will then queue the request and wake up the 
fetcher thread. The fetcher thread, when woken up, checks if the requested 
sector is already in the cache, and if it isn't, reads it from disk. 

The fetcher thread repeats this procedure for the entire duration of the 
program. Access to the request queue is synchronized using a dedicated lock.

---- SYNCHRONIZATION ----

>> C5: When one process is actively reading or writing data in a
>> buffer cache block, how are other processes prevented from evicting
>> that block?

Since the eviction policy is LRU, once a cache slot is about to 
be read from or written to, it is moved to the back of the queue of slots
eligible for eviction. Hence, a slot that is actively being read
from or written to is unlikely to be chosen for eviction.

When a process is about to read from or written to a buffer cache slot,
that process increments accessor counter on that cache slot.
If another process decides to evict a certain slot, it must wait until the 
number of accessors for that slot is zero. Thus it is blocked while other 
processes are actively reading from and writing to the slot. Note, however,
that having to wait here is highly unlikely and, indeed, will only happen 
when every block in the cache is being accessed simultaneously.


>> C6: During the eviction of a block from the cache, how are other
>> processes prevented from attempting to access the block?

During eviction of a block, we set a flag on that slot ('io-busy') to
be true. Whenever a process tries to access a block it must check the
io-busy flag. If it is set to true, the process must wait until the
eviction is complete. 

---- RATIONALE ----

>> C7: Describe a file workload likely to benefit from buffer caching,
>> and workloads likely to benefit from read-ahead and write-behind.

Buffer caching:
Repetitive accesses of the same memory location will benefit from
buffer caching, e.g. accessing a file will cause you to access that file's
inode sector repeatedly in order to find out where the file's data blocks are.

Read-ahead:
Sequential access of a file would benefit from read-ahead. For 
example playing a music or video file, where you know you are
going to want to read blocks from file in sequence.

Write-behind:
Any workload which didn't want to lose its data after an unexpected
system crash but also did not want to sacrifice performance would benefit 
from write-behind. Write-behind ensures that at most, only the most recent 
30 seconds of data will be lost.


			   SURVEY QUESTIONS
			   ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the TAs to more effectively assist
>> students in future quarters?

>> Any other comments?