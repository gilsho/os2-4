       	 +-------------------------+
		     | CS 140                  |
		     | PROJECT 4: FILE SYSTEMS |
		     | DESIGN DOCUMENT         |
		     +-------------------------+

---- GROUP ----

>> Fill in the names and email addresses of your group members.

Gil Shotan <gilsho@stanford.edu>
Rory MacQueen <macqueen@stanford.edu>
Dan Cocuzzo <dcocuzzo@stanford.edu>


---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Describe briefly which parts of the assignment were implemented by
>> each member of your team. If some team members contributed significantly
>> more or less than others (e.g. 2x), indicate that here.

All parts were implemented together with equal contribution.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

		     INDEXED AND EXTENSIBLE FILES
		     ============================

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

>> A2: What is the maximum size of a file supported by your inode
>> structure?  Show your work.

Our inode structure contains 12 direct sector pointers, 1 indirect block
pointer, and 1 doubly-indirect pointer. The indirect block contains 128 
direct sector pointers. The doubly-indirect block contains 128 indirect 
block pointers, which each contain 128 sector pointers. In total, there 
are 12 + 128 + 128^2 data sectors. Since each data sector is 512 bytes, the maximum size of a file is: 

(12 + 128 + 128^2) * (512) = 8460288 bytes = 8262 KB


If we include the overheard of allocating metadata, there are 130 additional
sectors (1 for the inode, 129 for indirect pointer tables), which
brings the total filesize to 8526848 bytes.

---- SYNCHRONIZATION ----

>> A3: Explain how your code avoids a race if two processes attempt to
>> extend a file at the same time.

Synchronization is enforced at the inode level for both files and
directories. Each inode contains a flag indicating if an extension
is in process and a condition variable associated with that extension 
flag. Read and write operations do not hold the inode during execution, 
however the lock must be acquired briefly to examine an inode's metadata 
(the extending flag and file length).

Only one process may extend a file at any given time. The kernel detects 
if an inode extension is necessary by examining the length of the inode
after a write operation. If an extension is necessary and the extension 
flag is clear, the process sets the extension flag, releases the lock,
and proceeds to allocate and write the extended region. If the process
attempts to extend but cannot because another is extending, the process 
waits on a condition variable until the previous extension is complete. 
Upon waking, it will determine again if an extension is necessary.

Once allocation and writing of the extended region is complete, the 
process reacquires the inode metadata lock and updates the file length 
to reflect the extension. This allows other processes  to read and write
(but not extend) the inode concurrently because they will not observe 
the change in file length until the extension is complete and therefore
will not attempt to access the extended file region.


>> A4: Suppose processes A and B both have file F open, both
>> positioned at end-of-file.  If A reads and B writes F at the same
>> time, A may read all, part, or none of what B writes.  However, A
>> may not read data other than what B writes, e.g. if B writes
>> nonzero data, A is not allowed to see all zeros.  Explain how your
>> code avoids this race.

Our implementation of file extension occurs 'behind the scenes' such
that any read operation by process A is oblivious to an ongoing extension
by process B. Since process B will synchronously update the file length
only after the extension (allocation and writing) is complete, process A 
will read all or none of the extended file region based the file length
it observed while briefly acquiring the inode metadata lock.


>> A5: Explain how your synchronization design provides "fairness".
>> File access is "fair" if readers cannot indefinitely block writers
>> or vice versa.  That is, many processes reading from a file cannot
>> prevent forever another process from writing the file, and many
>> processes writing to a file cannot prevent another process forever
>> from reading the file.




---- RATIONALE ----

>> A6: Is your inode structure a multilevel index?  If so, why did you
>> choose this particular combination of direct, indirect, and doubly
>> indirect blocks?  If not, why did you choose an alternative inode
>> structure, and what advantages and disadvantages does your
>> structure have, compared to a multilevel index?

We adopt the multilevel index scheme presented in lecture on our
inode structure, which contains direct, indirect, and doubly
idirect blocks. Given that the filesystem capacity is at most 8 MB, 
the 128*128 double indirect sectors sufficiently meet this size
requirement. We include 12 direct sector pointers for better
performance on smaller files (single disk seek), since the majority
of files are relatively small in practice. We include a single
sector for indirect pointer entries by convention, as well as
for improved seek times (two seeks) versus doubly indirect
accesses (3 seeks).

			    SUBDIRECTORIES
			    ==============

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

---- ALGORITHMS ----

>> B2: Describe your code for traversing a user-specified path.  How
>> do traversals of absolute and relative paths differ?

Given a valid user-specified path, we first determine if it is an 
absolute path or a relative path by examining the first character;
a leading '/' indicates it will be parsed as an absolute path. 

We determine the base directory (start_dir)

Our path traversal algorithm is an iterative approach. We tokenize 
the full path at '/' boundaries string using strtok_r, and 
handle the individual elements one-by-one.



---- SYNCHRONIZATION ----

>> B4: How do you prevent races on directory entries?  For example,
>> only one of two simultaneous attempts to remove a single file
>> should succeed, as should only one of two simultaneous attempts to
>> create a file with the same name, and so on.

There is a lock on each struct dir that are opened and in memory.
There is no need to synchronize readdir access operations, however
we enforce access control by acquiring the directory lock when entries 
are added or removed from the directory. These entry operations are
one component of creating and removing a file or directory, so threads 
only block during these sub-sections of code. 


>> B5: Does your implementation allow a directory to be removed if it
>> is open by a process or if it is in use as a process's current
>> working directory?  If so, what happens to that process's future
>> file system operations?  If not, how do you prevent it?

Our implementation allows for empty directories to be removed if it is
the current process' working directory or if it is in use by another
process. However, this prevents any process (including the current
process) from re-opening that directory, creating files 


---- RATIONALE ----

>> B6: Explain why you chose to represent the current directory of a
>> process the way you did.

A process' current working directory is stored as a struct dir on its 
thread structure. We chose to store the working directory on
the thread struct because all threads, including the main thread,
are intialized through the function. This is where inherit the parent
process' working directory, or set the working directory to root for
the main thread.


			     BUFFER CACHE
			     ============

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

---- ALGORITHMS ----

>> C2: Describe how your cache replacement algorithm chooses a cache
>> block to evict.

Our cache replacement is an implementation of LRU eviction. We maintain
a static list of cache entries that are not blocking on I/O, ordered
by least to most recently accessed time. When sectors that have existing
entries in the cache are accessed due to read/write operations, they are
move to the tail of the list. When eviction occurs, the LRU algorithm 
simply pops the entry at the front of the list, which is the least 
recently used entry. The new entry that is put in its place is appended 
to the tail of the LRU entry list.

>> C3: Describe your implementation of write-behind.

When the cache is initialized, a dedicated 'cleaner' thread is
spawned. This thread runs in a continuous while loop. It sleeps for 30
seconds, then wakes up and flushes the entire cache by writing all contents
to disk. It repeats this procedure for the entire duration of the program.

>> C4: Describe your implementation of read-ahead.

Our read ahead implementation consists of one thread running in the 
background and a queue of read ahead requests. When reading or writing 
to a file, call cache_fetch with the sector number of the next sector in 
the file. cache_fetch appends the sector number to the back of the fetch 
queue and wakes up the thread in charge of performing the read ahead. The 
read ahead thread, when woken up, places the contents of the requested 
sectors in the cache. The thread continues processing all requests and goes 
to sleep waiting for more requests to arrive. Access to the request queue is 
synchronized using a dedicated lock.

---- SYNCHRONIZATION ----

>> C5: When one process is actively reading or writing data in a
>> buffer cache block, how are other processes prevented from evicting
>> that block?

Firstly, since the eviction policy is LRU, once a block is about to 
be read from or written to, it is placed to the back of the queue of blocks
eligible for eviction. Hence, a block that is actively being read
from or written to is unlikely to be chosen for eviction.

When a process is about to read from or write to a buffer cache block,
that process increments the 'num_accessors' variable on that cache block.
If another process decides to evict a certain block, it must wait until the 
number of accessors for that block is zero. Thus it is blocked while other 
processes are actively reading from and writing to the sector. Note, however
that having to wait here is highly unlikely and, indeed, will only happen 
when every block in the cache is being used by some process.


>> C6: During the eviction of a block from the cache, how are other
>> processes prevented from attempting to access the block?

During eviction of a block, we set a flag on that block 'io-busy' to
be true. Whenever a process tries to access a block it must check the
io-busy flag. If it is set to true, the process must wait until the
eviction is complete. 

---- RATIONALE ----

>> C7: Describe a file workload likely to benefit from buffer caching,
>> and workloads likely to benefit from read-ahead and write-behind.

Buffer caching:
Repetitive accesses of the same memory location will benefit from
buffer caching, e.g. frequently changing the state of some character
in a game

Read-ahead:
Sequential access of a file would benefit from read-ahead. For 
example playing a music or video file, where you know you are
going to want to read later blocks in the file.

Write-behind:
Any workload which wanted to not lose all its data after an unexpected
system crash would benefit from write-behind, because the process could
be assured that at most, it only lost the most recent 30 seconds of 
data.


			   SURVEY QUESTIONS
			   ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the TAs to more effectively assist
>> students in future quarters?

>> Any other comments?